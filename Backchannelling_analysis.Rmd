---
title: "Анализ триггеров обратной связи в диалоге"
output: html_document
date: "2024-06-04"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

## Описание данных

### Теория

Обратная связь (в англоязычной литературе также называемая
backchanneling, feedback и listener responses, далее ОС) – это сигналы
от слушающего к говорящему, которые не приводят к смене ролей
коммуникантов и происходят параллельно с речью говорящего. Она
показывает, понимает ли слушающий говорящего и как именно, а также как
слушающий реагирует на сообщаемое.

В данном проекте будет исследована зависимость появления сигналов ОС от
границ ЭДЕ и пауз в речи говорящего, а также от направления взгляда
коммуникантов. Проверяемая гипотеза:

-   H0: Появление ОС не зависит от напревления взгляда испытуемых и их
    собеседников, от пауз в речи собеседника и от границ ЭДЕ в речи
    собеседника;

-   Н1: Появление ОС зависит от исследуемых переменных (или части из
    них).

Обоснованность исследования этой гипотезы подкрепляется следующими
исследованиями:

В [Truong et al. 2011] было показано, что ОС часто происходит возле
конца речевого сегмента. Вокальная обратная связь с вероятностью выше
случайной происходит в паузах, в то время как визуальная не склонна к
этому. В [Morency 2010] как один из триггеров указывается долгая пауза.
В заполненных же паузах ОС не происходит вовсе ([Koiso et al. 1998]).

Также в [Truong et al. 2011] показано, что зрительный контакт является
сильным триггером ОС, причём как для вокальной, так и для визуальной,
хотя для вокальной зависимость несколько слабее. Это объясняется тем,
что при зрительном контакте слушающий уверен, что его визуальная ОС
будет замечена говорящим. При этом важно отметить (для дальнейшего
анализа), что во время и сразу после ОС количество зрительного контакта
снижается. Синхронизация движений слушающего и говорящего (также иногда
считающаяся ОС) в исследовании [Koutsombogera, Papageorgiou 2010] также
происходила только во время зрительного контакта между коммуникантами.

### Сбор видеоданных (описание эксперимента)

В качестве данных для проверки основной гипотезы были выбраны
видеозаписи, сделанные в ходе эксперимента [Вашпанова 2021]. В этом
эксперименте каждой паре участников предлагалось сыграть друг с другом в
игру на объяснение слов по следующим правилам: в течение своего хода
участник поочерёдно берёт карточки со словами из лежащей рядом с ним
стопки (все карточки лежат рубашкой вверх, чтобы партнёр участника не
мог видеть слова) и объясняет эти слова, не называя их сами, а также не
используя однокоренные им слова и их переводы на другие языки (однако
просить партнёра перевести что-то на иностранный язык было можно). Когда
партнёр отгадывал одно слово, участник откладывал карточку с ним в сброс
и брал следующую. За один ход можно было объяснить любое число слов. На
ход участнику давалось 30 секунд, после чего подавался сигнал стоп, и
тогда у его партнёра была возможность, произнеся ровно одно слово,
высказать последнюю свою догадку. Если она оказывалась верной, то
текущее слово скидывалось в сброс, если же нет – участник откладывал его
до своего следующего хода. После этого подавался сигнал о начале хода
партнёра. Таким образом участники поочерёдно объясняли друг другу слова,
пока у одного из них не заканчивалась стопка. Тогда объявлялся
«бесконечный» ход второго участника, в который он должен был дообъяснить
все оставшиеся у него карточки. Также при возникновении слишком
серьёзных трудностей была возможность сбросить карточку, однако
участникам не рекомендовалось этого делать. Их задачей было объяснить
как можно большее количество слов за как можно меньшее время.

Перед началом эксперимента паре участников зачитывалась инструкция,
после чего каждому из них предлагалось объяснить одно тестовое слово.
Затем начиналась сама игра. Также у участников была возможность в любой
момент эксперимента попросить сделать паузу, если у них возникали
вопросы по правилам игры. В качестве стимульного материала было
составлено два списка по десять слов в каждом, идущих в фиксированном
порядке. Словами были существительные русского языка из разных областей
знаний в именительном падеже единственного числа (от бытовых приборов и
животных до терминов).

Для данной работы было отобрано 5 видеозаписей участников младшей
возрастной группы (19-21 год), и в каждой из них был выбран один из
участников таким образом, чтобы все анализируемые участники отгадывали
один и тот же список слов. Далее из каждого видео были отобраны те
фрагменты, в которых эти участники отгадывали слова ЭКСЦЕНТРИЧНОСТЬ,
МУРЕНА, СИТЕЧКО, АНАРХИЗМ и СУПНИЦА (с этими словами справилось
наибольшее количество участников, они достаточно разнообразны по форме,
семантике и сложности, а также идут подряд в середине экспериментального
списка, что позволяет минимально разрывать дискурс участников и смягчает
возможный эффект начальной адаптации к правилам). Далее были размечены
релевантные движения выбранных участников в этих фрагментах, а также
направление взгляда их и их партнёров, размечена речь партнёра по ЭДЕ и
паузам.

Эти данные были выбраны по нескольким причинам. Во-первых, они позволяют
отобрать достаточно (или же и вовсе максимально) схожие по содержанию
контексты для анализа и снизить влияние возможной разницы между ними на
итоговый результат, при этом сохраняя некоторую степень экологичности
данных. Во-вторых, данная структура эксперимента позволяет достаточно
легко отобрать те места, где рассматриваемый участник находится в роли
слушающего, поскольку из-за ограничения по времени участникам невыгодно
перебивать друг друга. Игровой характер эксперимента также имеет свои
преимущества. С одной стороны, это в очень высокой степени кооперативное
задание, что может повышать количество обратной связи (см. [Bavelas,
Coates, Johnson 2000]), с другой же, ограничение по времени и элемент
соревнования делают коммуникацию участников более эмоциональной, что
может увеличить количество зрительного контакта (см. [Федорова 2019]).
Дополнительным плюсом в данном случае можно считать и то, что, в отличие
от схожих по характеру заданий по картам (как, например, в [Koiso et al.
1998]), участники имеют возможность постоянно видеть друг друга и их
руки ничем не заняты.

В каждой паре оба участника были друг с другом хорошо знакомы, что, по
мнению [White 1989], может помочь исключить из анализа возможные
особенности обратной связи при первом взаимодействии. Таким образом, все
рассмотренные участники были сбалансированы по возрасту, статусу (все
они являются студентами одного факультета) и отношению друг к другу, а
также все они являются носителями русского языка как первого. Во всех
парах участники были одного пола, в четырёх случаях женского и в одном
мужского.

### Разметка данных

Разметка проводилась в программе ELAN 6.4 в 9 слоях (по одному слою на
каждый рассматриваемый канал и дополнительные слои для движений глаз
партнёра и его речи), где для каждого релевантного действия отмечался
временной отрезок, в который оно происходило, и его тег (жест или смена
позы для сигналов обратной связи, заполненная или абсолютная пауза,
направление взгляда на партнёра или на экспериментатора, содержание
ЭДЕ).

В качестве начала сигнала обратной связи отмечалось начало его
экскурсии. Определение сигналов происходило по следующим принципам (по
рабочему определению [Ward, Tsukahara 2000]): 1) обратная связь напрямую
относится к содержанию высказывания говорящего; 2) обратная связь
необязательна; 3) обратная связь не требует ответной реакции
(acknowledgement).

Помимо жестов размечались средние и крупные смены позы (затрагивающие не
меньше кисти или ступни), поскольку в [Вашпанова 2022] было показано,
что смены позы могут быть связаны в том числе с дискурсивными границами
в диалоге, а потому могут являться одним из видов обратной связи
(сигналами совпадения по классификации [O’Keeffe, Adolphs 2008]).

Те движения, что были синхронизированы с репликами участника в роли
говорящего (в связи с дизайном эксперимента таких реплик было достаточно
мало, но несколько раз они встретились) или же сами были по сути такой
репликой (например, эмблематические жесты вроде [поднести палец к губам
и вытянуть ладонь к собеседнику в знаке стоп]) из анализа исключались.

Разметка взгляда проводилась исключительно по видео, без использования
айтрекера. Несмотря на меньшую точность, такой метод до сих пор
используется в различных исследованиях невербального поведения (см.
[Leinonen 2022], [Kidwell, Reynolds 2022]) и кажется допустимым и в
данной работе с целью упростить сбор материала.

ЭДЕ выделялись в первую очередь на основании интонационных контуров, а
также пауз и семантики, в соответствии с [Кибрик, Подлесская 2006].

## Визуализация

```{r}
library(tidyverse)
data <- read.csv('C:/Users/USER/Desktop/Учебное/ВШЭ/final_project_data_Vashpanova.csv')
```

Посмотрим на количество жестов/смен позы в разных каналах и их
соотношение:

```{r}
data %>%
  filter(Name == 'gesture' | Name == 'ps') %>%
  group_by(Layer, Participant) %>%
  count() %>%
  ungroup(Layer) %>%
  arrange(desc(Layer)) %>%
  mutate(prop = n / sum(.$n) *100) %>%
  mutate(ypos = cumsum(prop) - 0.5*prop) %>%
  ggplot(aes(x="", y=prop, fill=Layer)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  facet_wrap(Participant~., scales='free') +
  theme_void() +
  geom_text(aes(x=1.7, y = ypos, label = n), color = "black", size=3.5) +
  scale_fill_viridis_d(option = "mako", begin=0.2, end=0.8, labels=c("Туловище",
                                                                     "Брови",
                                                                     "Руки",
                                                                     "Голова",
                                                                     "Ноги",
                                                                     "Губы")) +
  labs(fill = "Канал")
```

Теперь посмотрим на соотношение жестов и смен позы:

```{r}
data %>%
  filter(Name == 'gesture' | Name == 'ps') %>%
  group_by(Name, Participant) %>%
  count() %>%
  ungroup(Name) %>%
  arrange(desc(Name)) %>%
  mutate(prop = n / sum(.$n) *100) %>%
  mutate(ypos = cumsum(prop) - 0.5*prop) %>%
  ggplot(aes(x="", y=prop, fill=Name)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  facet_wrap(Participant~., scales='free') +
  theme_void() +
  geom_text(aes(x=1.7, y = ypos, label = n), color = "black", size=3.5) +
  scale_fill_viridis_d(option = "mako", begin=0.2, end=0.7, labels=c("Жест",
                                                                     "Смена позы")) +
  labs(fill = "Тип")
```

Зрительное поведение испытуемых и их партнёров:

```{r}
data %>%
  filter(Name == 'op') %>%
  group_by(Layer, Participant) %>%
  count() %>%
  ungroup(Layer) %>%
  arrange(desc(Layer)) %>%
  mutate(prop = n / sum(.$n) *100) %>%
  mutate(ypos = cumsum(prop) - 0.5*prop) %>%
  ggplot(aes(x="", y=prop, fill=Layer, color=Layer)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  theme_void() +
  geom_text(aes(x=1.7, y = ypos, label = n), color = "black", size=3.5) +
  scale_fill_viridis_d(option = "mako", begin=0.3, end=0.7, labels=c('участник > партнёр', 'партнёр > участник')) +
  facet_wrap(Participant~., scales='free') +
  labs(fill = "Направление взгляда")
  
```

Вероятно, стоит проверить данные N0106 или исключить его из анализа.

Посмотрим на соотношение типов пауз:

```{r}
data %>%
  filter(Layer == 'PausesOp') %>%
  group_by(Name, Participant) %>%
  count() %>%
  ungroup(Name) %>%
  arrange(desc(Name)) %>%
  mutate(prop = n / sum(.$n) *100) %>%
  mutate(ypos = cumsum(prop) - 0.5*prop) %>%
  ggplot(aes(x="", y=prop, fill=Name)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  theme_void() +
  geom_text(aes(x=1.7, y = ypos, label = n), color = "black", size=3.5) +
  scale_fill_viridis_d(option = "mako", begin=0.3, end=0.7, labels=c("абсолютная", "заполненная")) +
  facet_wrap(Participant~., scales='free') +
  labs(fill = "Пауза")
```

Процент времени, который занимают выделеннные явления от общего времени
анализируемых записей (паузы, ЭДЕ, взгляд участника на партнёра и взгляд
партнёра на участника):

```{r}
data %>%
  select(Participant, Duration, Layer) %>%
  filter(Layer %in% c('EyesOp', 'Eyes', 'PausesOp', 'EDUop', 'Turns')) %>%
  group_by(Participant) %>%
  pivot_wider(names_from = Layer,
              values_from = Duration,
              values_fn = sum) %>%
  mutate(Participant=Participant,
         Total.time = Turns,
         Pauses = 100*PausesOp/Turns,
         EDU = 100*EDUop/Turns,
         `Participant>Partner` = 100*Eyes/Turns,
         `Partner>Participant` = 100*EyesOp/Turns,
         .keep='none') %>%
  arrange(Participant)
```

## Анализ

### Предобработка

Для анализа этих данных необходимо их предобработать. Чтобы получить
негативные данные (условия, при которых не появился сигнал ОС), разобьём
всё время записей на промежутки по 0.7 секунд. Этот промежуток выбран
как оптимальный, поскольку 1) он попадает в область влияния контекста
на появление обратной связи и 2) он в полтора раза короче среднего периода
появления сигнала ОС (что позволит несколько нивелировать перевес
отрицательных данных)

Средний период появления сигналов:

```{r}
data %>%
  filter(Layer=='Turns') %>%
  summarize(freq = sum(Duration)/data %>% filter(Name %in% c('gesture', 'ps')) %>% count()) %>%
  unnest()
```

Для предобработки было написано две функции. Первая (context_space)
определяет, входит ли временая точка в промежуток рассматриваемых
триггеров (взгляд испытуемого на партнёра, взгляд партнёра на
испытуемого, ЭДЕ, заполненная пауза, абсолютная пауза). Вторая
(context_point) определяет, произошёл ли во окрестностях точки триггер
(начало ЭДЕ, конец ЭДЕ) и сигнал ОС (только в правой части окрестности).

```{r}
context_space <- function(n, s) {
  context <- data %>%
    filter(Participant == n, Start<=s, End>=s)
    
  return(
    data.frame(
      p2o = nrow(filter(context, Layer=='Eyes', Name=='op')),
      o2p = nrow(filter(context,Layer=='EyesOp', Name=='op')),
      edu = nrow(filter(context,Layer=='EDUop', Name!='*смех*')),
      vp = nrow(filter(context,Layer=='PausesOp', Name=='voiced')),
      mp = nrow(filter(context,Layer=='PausesOp', Name=='mute'))
      )
    )
}

context_point <- function(n, s) {
  context <- data %>%
    filter(Participant == n, Name!='*смех*')
    
  return(
    data.frame(
      eend = nrow(context %>% filter(Layer=='EDUop', End-0.7<=s, End+0.7>=s)),
      estart = nrow(context %>% filter(Layer=='EDUop', Start-0.7<=s, Start+0.7>=s)),
      bch = nrow(context %>%
                   filter(Layer %in% c('Lips', 'Brows', 'Hands', 'Legs', 'Body', 'Head'),
                                    Start>=s, Start-0.7<=s))
      )
    )
}
```

Затем с шагом 0.7 был собран набор временных точек и определены их
характеристики по двум вышеописанным функциям. Точки, находящиеся менее
чем в 0.35 секундах от конца записи, были исключены из анализа.
Зрительный контакт рассчитывался как совпадение предикторов "взгляд
испытуемого на партнёра" и "взгляд партнёра на испытуемого".

```{r}
timeline <- data.frame()

for (p in unique(data$Participant)) {
  for (t in unique(filter(data, Layer=='Turns')$Name)) {
    start = filter(data, Participant==p, Name==t)$Start
    end = filter(data, Participant==p, Name==t)$End
    
    if (length(start)) {
      df <- data.frame(
          participant = p,
          turn = t,
          s = seq(start, end, by = 0.7)) %>%
          mutate(e = s+0.7)
      df$e[nrow(df)] = end
      timeline <- timeline %>%
        rbind( df %>% mutate(dur = e-s) )
    }
  }
}

timeline <- timeline %>%
  mutate(space = map2(participant, s, context_space),
         point = map2(participant, s, context_point)) %>%
  unnest(space, point)
```

```{r}
timeline <- timeline %>%
  mutate(p2o = as.logical(p2o),
         o2p = as.logical(o2p),
         edu = as.logical(edu),
         vp = as.logical(vp),
         mp = as.logical(mp),
         eend = as.logical(eend),
         estart = as.logical(estart),
         bch = as.logical(bch),
         eyecont = p2o&o2p)

timeline <- timeline %>%
  filter(dur>=0.35)

timeline %>%
  summary()
```

Мы можем видеть, что дисбаланс данных по сигналам ОС не слишком большой
(FALSE:546 vs TRUE :353).

Для удобства анализа значения переменных были приведены к числовым
показателям 0 и 1. Для паузы было выбрано три уровня: отсутствие,
заполненная, абсолютная (0, 1, 2), поскольку предикторы "заполненная
пауза" и "абсолютная пауза" взаимоисключающие.

```{r}
timeline <- timeline %>%
  mutate(participant = as.factor(participant),
         turn = as.factor(turn),
         p2o = as.integer(p2o),
         o2p = as.integer(o2p),
         edu = as.integer(edu),
         eend = as.integer(eend),
         estart = as.integer(estart),
         bch = as.integer(bch),
         eyecont = as.integer(eyecont),
         vp = as.integer(vp),
         mp = as.integer(mp),
         pause = case_when(vp==1 ~ 1, mp==1 ~ 2, .default = 0)
         )
```

Датасет не содержит пропусков в данных:

```{r}
sum(is.na(timeline))
```

Абсолютно коллинеарные предикторы отсутствуют, однако некоторые сильно
коррелированы (ЭДЕ и абсолютная пауза, пауза и абсолютная пауза,
зрительный контакт и направление взгляда):

```{r}
cor(timeline[6:15])
```

### Построение модели

Поскольку выше было показано, что испытуемые различаются по своему
поведению ОС и взгляда, на анализа используется модель со случайным
коэффициентом "participant" (только intercept).

```{r}
library(lme4)

fit_lme <- glmer(bch ~ pause * p2o * o2p * eend * estart * edu + (1|participant), data = timeline, family = 'binomial')
summary(fit_lme)
drop1(fit_lme, test = 'Chisq')
```

Первая модель, включающая все факторы, кроме абсолютной паузы и
заполненной паузы (целиком описывамых переменной pause) и зрительного
контакта (описываемого взаимодействием направлений взгляда), и их
взаимодействия, не сошлась. Поэтому далее была построена модель, которая
учитывает:

-   направление взгляда, паузу и их взаимодействие (поскольку во время
    паузы поведение взгляда может регулировать передачу роли говорящего,
    чего слушающий старается избежать в нашем контексте);

-   взаимодействие направления взгляда и близости концов ЭДЕ (также
    направление взгляда может быть важным триггером передачи роли
    говорящего на границах речевых сегментов);

-   контекст внутри ЭДЕ.

Далее отбор значимых предикторов проводился методом drop1.

```{r}
fit_lme_1<-glmer(bch ~ pause * p2o * o2p + (eend + estart) * o2p + (eend + estart) * p2o + edu + (1|participant), data = timeline, family = 'binomial')
summary(fit_lme_1)
drop1(fit_lme_1, test = 'Chisq')

fit_lme_2 <- update(fit_lme_1, .~. -pause:p2o:o2p)
summary(fit_lme_2)
drop1(fit_lme_2, test = 'Chisq')

fit_lme_3 <- update(fit_lme_2, .~. -p2o:eend)
summary(fit_lme_3)
drop1(fit_lme_3, test = 'Chisq')

fit_lme_4 <- update(fit_lme_3, .~. -edu)
summary(fit_lme_4)
drop1(fit_lme_4, test = 'Chisq')

fit_lme_5 <- update(fit_lme_4, .~. -p2o:estart)
summary(fit_lme_5)
drop1(fit_lme_5, test = 'Chisq')

fit_lme_6 <- update(fit_lme_5, .~. -pause:p2o)
summary(fit_lme_6)
drop1(fit_lme_6, test = 'Chisq')

fit_lme_7 <- update(fit_lme_6, .~. -o2p:estart)
summary(fit_lme_7)
drop1(fit_lme_7, test = 'Chisq')

fit_lme_8 <- update(fit_lme_7, .~. -p2o:o2p)
summary(fit_lme_8)
drop1(fit_lme_8, test = 'Chisq')

fit_lme_9 <- update(fit_lme_8, .~. -p2o)
summary(fit_lme_9)
drop1(fit_lme_9, test = 'Chisq')

fit_lme_10 <- update(fit_lme_9, .~. -pause:o2p)
summary(fit_lme_10)
drop1(fit_lme_10, test = 'Chisq')

fit_lme_11 <- update(fit_lme_10, .~. -pause)
summary(fit_lme_11)
drop1(fit_lme_11, test = 'Chisq')
```

Дальнейшее сокращение модели приведёт к снижению качества (estart: AIC =
1204.1, LRT = 5.7996, Pr(Chi) = 0.016029 \< .05, o2p:eend: AIC = 1206.8,
LRT = 8.5343, Pr(Chi) = 0.003485 \< .01).

Полученная модель значимо лучше, чем нулевая (нулевая: npar = 2, AIC =
1208.5, BIC = 1218.1, logLik = -602.26, deviance = 1204.5, целевая
модель: npar = 6, AIC = 1200.3, BIC = 1229.1, logLok = -594.14, deviance
= 1188.3, значимость: Chisq(4) = 16.241, p-value \< .01).

```{r}
fit_lme_null <- glmer(bch ~ 1 + (1|participant), family = 'binomial', timeline)
anova(fit_lme_null, fit_lme_11)
```

Изменение AIC при сокращении модели:

```{r}
AIC(fit_lme, fit_lme_1, fit_lme_2, fit_lme_3, fit_lme_4, fit_lme_5, fit_lme_6,
    fit_lme_7, fit_lme_8, fit_lme_9, fit_lme_10, fit_lme_11)
```

Изменение BIC при сокращении модели:

```{r}
BIC(fit_lme, fit_lme_1, fit_lme_2, fit_lme_3, fit_lme_4, fit_lme_5, fit_lme_6,
    fit_lme_7, fit_lme_8, fit_lme_9, fit_lme_10, fit_lme_11)
```

Можно видеть, что текущая модель обладает оптимальными значениями AIC и
BIC.

Далее необходимо прверить модель на нарушения линейности:

```{r}
fit_lme_11 %>%
  fortify.merMod() %>%
  ggplot(aes(x = .fitted, y = .scresid)) +
  geom_point() +
  geom_smooth()
```

Нарушения линейности есть, но достаточно небольшие, поэтому можем ими
пренебречь.

Проверка модели на чрезмерную дисперсию:

```{r}
library(performance)
check_overdispersion(fit_lme_11)
```

Чрезмерной дисперсии не обнаружено (dispersion ratio = 1.004, p-value \>
0.05).

### Анализ данных модели

```{r}
summary(fit_lme_11)
```

Появление сигнала ОС значимо зависит от: \* направления взгляда партнёра
на участника (coef = 0.7260, error = 0.1471, z-value = -3.902, p-value
\< .01) \* конца ЭДЕ (coef = 0.4937, error = 0.1820, z-value = 2.939,
p-value \< .01) \* начала ЭДЕ (coef = -0.3637, error = 0.1512, z-value =
-2.405, p-value \< .05) \* взаимодействия направления взгляда партнёра
на участника и конца ЭДЕ (coef = -0.8726, error = 0.2993, z-value =
-2.916, p-value \< .01)

```{r}
icc(fit_lme_11)
```

Значения ICC модели очень мало, поэтому влияние случайного фактора
участника невелико.

### Качественный анализ

Чтобы более наглядно представить данные, выведем в отдельный столбец
предсказания модели.

```{r}
timeline %>% mutate(predicted = predict(fit_lme_11, type = 'response')) -> timeline
```

Визуализируем переменные, использованные в модели:

```{r}
timeline %>%
  group_by(o2p, eend, estart) %>%
  ggplot(aes(x=as.factor(eend), y=predicted, color=as.factor(o2p))) +
  geom_boxplot() +
  facet_wrap(.~estart, labeller = labeller(estart = ~if_else(.x==0, "Не начало ЭДЕ", "Начало ЭДЕ"))) +
  theme_light() +
  scale_color_viridis_d(option = "mako", begin=0.2, end=0.8, labels = c("Нет", "Да")) +
  labs(x = "Конец ЭДЕ", color = "партнёр > участник") +
  scale_x_discrete(labels = c("Нет", "Да"))
```

Можно заметить, что: 1) близость к началу ЭДЕ снижает вероятность появления сигнала ОС; 2) вблизи от конца ЭДЕ направление взгляда партнёра на участника снижает вероятность появления ОС, в то время как 3) вне близости к концу ЭДЕ направление взгляда партнёра на участника наоборот повышает её.

Снижение вероятности ОС в окрестностях начала ЭДЕ можно объяснить малым
количеством информации в этой области, требующей рекации. К концу ЭДЕ её
становится больше и вероятность повышается. Также более осмысленно
давать сигналы ОС тогда, когда партнёр может это увидеть. Взаимодействие
же факторов можно можно объяснить особенностями перехода роли говорящего
к слушающему: вблизи от конца ЭДЕ есть большой риск перехода роли, и
чтобы этого не допустить, говорящий скорее отведёт взгляд, и в таком
случае слушающему можно более свободно сигнализировать ОС, не боясь
перебить очередь говорящего.

Посмотрим также на влияние других факторов, не вошедших в изначальную
модель: двух типов пауз и зрительного контакта.

```{r}
timeline %>%
  group_by(o2p, eend, vp) %>%
  ggplot(aes(x=as.factor(eend), y=predicted, color=as.factor(o2p))) +
  geom_boxplot() +
  facet_wrap(.~vp, labeller = labeller(vp = ~if_else(.x==0, "Не в заполненной паузе", "В заполненной паузе"))) +
  theme_light() +
  scale_color_viridis_d(option = "mako", begin=0.2, end=0.8, labels = c("Нет", "Да")) +
  labs(x = "Конец ЭДЕ", color = "партнёр > участник") +
  scale_x_discrete(labels = c("Нет", "Да"))
```

Согласно модели, наличие заполненной паузы снижает вероятность появления
сигнала ОС в отсутствие конца ЭДЕ и взгляда партнёра на испытуемого.
Интересно также то, что в датасете не встретилось ни одного случая
заполненной паузы, когда рядом есть конец ЭДЕ и партнёр смотрит на
испытуемого.

```{r}
timeline %>%
  group_by(o2p, eend, mp) %>%
  ggplot(aes(x=as.factor(eend), y=predicted, color=as.factor(o2p))) +
  geom_boxplot() +
  facet_wrap(.~mp, labeller = labeller(mp = ~if_else(.x==0, "Не в абсолютной паузе", "В абсолютной паузе"))) +
  theme_light() +
  scale_color_viridis_d(option = "mako", begin=0.2, end=0.8, labels = c("Нет", "Да")) +
  labs(x = "Конец ЭДЕ", color = "партнёр > участник") +
  scale_x_discrete(labels = c("Нет", "Да"))
```

Наличие абсолютной паузы немного сглаживает разницу в вероятностях при
взаимодействии конца ЭДЕ и взгляда партнёра на участника и в целом
немного повышает вероятност появления ОС.

```{r}
timeline %>%
  group_by(o2p, eend, eyecont) %>%
  ggplot(aes(x=as.factor(eend), y=predicted, color=as.factor(o2p))) +
  geom_boxplot() +
  facet_wrap(.~eyecont, labeller = labeller(eyecont = ~if_else(.x==0, "Нет зрительного контакта", "Есть зрительный контакт"))) +
  theme_light() +
  scale_color_viridis_d(option = "mako", begin=0.2, end=0.8, labels = c("Нет", "Да")) +
  labs(x = "Конец ЭДЕ", color = "партнёр > участник") +
  scale_x_discrete(labels = c("Нет", "Да"))
```

Согласно модели, зрительный контакт при фиксированном направлении
взгляда партнёра на участника никак не влияет на вероятности появления
ОС.

## Выводы

В этом анализе было показано, что появление сигналов ОС значимо
повышается при направления взгляда говорящего на слушающего и возле
конца ЭДЕ и значимо понижается вблизи начала ЭДЕ. Взаимодействие
направления взгляда и конца ЭДЕ меняет эффект направления взгляда на
противоположный. Влияние остальных факторов (заполненных и абсолютных
пауз, направления взгляда испытуемого на партнёра и зрительного
контакта, а также контекста внутри эде) не оказалось статистически
значимым.

Таким образом, мы может отвергнть нулевую гипотезу о независимости
сигналов ОС от направления взгляда и сегментов речи, но не о
независимости от пауз.

## Литература

1.  *Вашпанова К. В.* Сравнение жестикуляции в разных социальных
    группах: смены позы у людей разного возраста. Экспериментальное
    исследование //Курсовая работа, рукопись – 2021.

2.  *Вашпанова К. В.* Отражение глобальной структуры дискурса в сменах
    позы коммуникантов //Курсовая работа, рукопись – 2022.

3.  *Кибрик А. А., Подлесская В. И.* Проблема сегментации устного дискурса
    и когнитивная система говорящего //Когнитивные исследования. – 2006.
    – С. 138-158.

4.  *Федорова О. В.* О коммуникативной функции взгляда //Труды института
    русского языка им. ВВ Виноградова. – 2019. – Т. 21. – С. 222-241.

5.  *Bavelas J. B., Coates L., Johnson T.* Listeners as co-narrators
    //Journal of personality and social psychology. – 2000. – Т. 79. –
    №. 6. – С. 941.

6.  *Kidwell M., Reynolds E.* Gaze and the Organization of Participation
    in Collective Visual Conduct [Электронный ресурс] //Social
    Interaction. Video-Based Studies of Human Sociality. – 2022. – Т. 5.
    – №. 2. – URL: <https://doi.org/10.7146/si.v5i2.119332> (дата
    обращения 10.05.2023)

7.  *Koiso H. et al.* An analysis of turn-taking and backchannels based
    on prosodic and syntactic features in Japanese map task dialogs
    //Language and speech. – 1998. – Т. 41. – №. 3-4. – С. 295-321.

8.  *Koutsombogera M., Papageorgiou H.* Linguistic and non-verbal cues
    for the induction of silent feedback //Proceedings of the Second
    international conference on Development of Multimodal Interfaces:
    active Listening and Synchrony. – 2009. – С. 327-336.

9.  *Leinonen I.* Multimodal Try-marking for Securing Recipient
    Understanding of Codeswitched Lexical Items in Everyday ELF
    Conversations [Электронный ресурс] //Social Interaction. Video-Based
    Studies of Human Sociality. – 2022. – Т. 5. – №. 2. – URL:
    <https://doi.org/10.7146/si.v5i2.124481> (дата обращения 10.05.2023)

10. *Morency L. P.* Modeling human communication dynamics [social
    sciences] //IEEE Signal Processing Magazine. – 2010. – Т. 27. –
    №. 5. – С. 112-116.

11. *O’Keeffe A., Adolphs S.* Response tokens in British and Irish
    discourse //Variational pragmatics. – 2008. – С. 69-98.

12. *Truong K. P. et al.* A Multimodal Analysis of Vocal and Visual
    Backchannels in Spontaneous Dialogs //INTERSPEECH. – 2011. – С.
    2973-2976.

13. *Ward N., Tsukahara W.* Prosodic features which cue back-channel
    responses in English and Japanese //Journal of pragmatics. – 2000. –
    Т. 32. – №. 8. – С. 1177-1207.

14. *White S.* Backchannels across cultures: A study of Americans and
    Japanese //Language in society. – 1989. – Т. 18. – №. 1. – С. 59-76.
